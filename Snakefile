# Snakefile for MeDIP-seq analysis pipeline

# Import necessary libraries
import glob
from os.path import join
import os

# Load configuration file
configfile: "config.yaml"

# Get all sample names - keep exactly as they appear in the files
SAMPLES = glob.glob("medip/Medip_*_*_r*.fastq.gz")
SAMPLES = [s.split("/")[-1].replace(".fastq.gz", "") for s in SAMPLES]

# Debug print to see what we're getting
print("Raw SAMPLES:", SAMPLES)

# Separate input and IP samples (make case-insensitive)
INPUT_SAMPLES = [s for s in SAMPLES if "input" in s.lower()]
IP_SAMPLES = [s for s in SAMPLES if "output" in s.lower()]

# Get conditions (DP, PP, N)
CONDITIONS = list(set([s.split('_')[1] for s in SAMPLES]))  # Will give you ['DP', 'N', 'PP']

# After sample detection - debug prints
print("Detected samples:", SAMPLES)
print("Input samples:", INPUT_SAMPLES)
print("IP samples:", IP_SAMPLES)
print("Conditions:", CONDITIONS)

# Create output directories if they don't exist
for dir_name in ["trimmed_outdir", "fastqc_outdir", "aligned_outdir", "dedup_outdir", 
                 "peaks_outdir", "diff_meth_outdir", "func_annot_outdir", "qc_outdir", 
                 "bigwig_outdir", "meth_level_outdir"]:
    os.makedirs(config[dir_name], exist_ok=True)

# Add this near the top of the file, after imports
REQUIRED_DIRS = ["logs/trimmomatic", "logs/fastqc_trimmed", "logs/mark_duplicates",
                "logs/call_peaks", "logs/create_bigwig"]
for dir_name in REQUIRED_DIRS:
    os.makedirs(dir_name, exist_ok=True)

# Define the final output files that should be generated by the pipeline
rule all:
    input:
        # FastQC output for raw reads
        expand(join(config["fastqc_outdir"], "{sample}_fastqc.html"), 
               sample=SAMPLES),  # Remove "Medip_" prefix as it's already in SAMPLES
        # Sorted BAM files after alignment
        expand(join(config["aligned_outdir"], "{sample}_sorted.bam"), 
               sample=SAMPLES),
        # Peak calling results
        expand(join(config["peaks_outdir"], "{condition}_{replicate}_peaks.narrowPeak"), 
               condition=CONDITIONS, replicate=["r1", "r2", "r3"]),
        # Differential methylation results
        join(config["diff_meth_outdir"], "differential_methylation_results.txt"),
        # Functional annotation results
        join(config["func_annot_outdir"], "go_enrichment_results.csv"),
        join(config["func_annot_outdir"], "kegg_enrichment_results.csv"),
        # MultiQC report
        join(config["qc_outdir"], "multiqc_report.html"),
        # BigWig files for visualization
        expand(join(config["bigwig_outdir"], "{sample}.bw"), sample=SAMPLES),
        # Additional QC plots and metrics
        join(config["qc_outdir"], "fragment_size_distribution.pdf"),
        join(config["qc_outdir"], "cpg_enrichment.txt"),
        join(config["qc_outdir"], "replicate_correlation.pdf"),
        join(config["meth_level_outdir"], "methylation_levels.txt")

# Rule to run FastQC on raw reads
rule fastqc:
    input:
        "medip/{sample}.fastq.gz"  # {sample} now includes "Medip_" prefix
    output:
        html = join(config["fastqc_outdir"], "{sample}_fastqc.html"),
        zip = join(config["fastqc_outdir"], "{sample}_fastqc.zip")
    log:
        "logs/fastqc/{sample}.log"
    shell:
        """
        fastqc {input} -o {config[fastqc_outdir]}/ 2> {log}
        """

# Rule to trim adapters and low-quality bases using Trimmomatic
rule trimmomatic:
    input:
        "medip/{sample}.fastq.gz"
    output:
        trimmed=join(config["trimmed_outdir"], "{sample}_trimmed.fastq.gz")
    log:
        "logs/trimmomatic/{sample}.log"
    threads: 4
    shell:
        """
        trimmomatic SE -threads {threads} \
            {input} \
            {output.trimmed} \
            ILLUMINACLIP:{config[adapters]}:2:30:10 \
            LEADING:3 TRAILING:3 SLIDINGWINDOW:4:15 MINLEN:36 \
            2> {log}
        """

# Rule to run FastQC on trimmed reads
rule fastqc_trimmed:
    input:
        join(config["trimmed_outdir"], "{sample}_trimmed.fastq.gz")
    output:
        join(config["fastqc_outdir"], "{sample}_trimmed_fastqc.html")
    log:
        "logs/fastqc_trimmed/{sample}.log"
    shell:
        """
        fastqc {input} -o {config[fastqc_outdir]}/ 2> {log}
        """

# Rule to align reads to the reference genome using Bowtie2
rule align:
    input:
        join(config["trimmed_outdir"], "Medip_{sample}_trimmed.fastq.gz")
    output:
        join(config["aligned_outdir"], "Medip_{sample}.bam")
    params:
        index = config["genome_index"]
    threads: config["threads"]
    log:
        "logs/align/{sample}.log"
    shell:
        """
        set -e
        set -o pipefail
        bowtie2 -p {threads} -x {params.index} -U {input} 2> {log} | \
        samtools view -bS - > {output}
        """

# Rule to sort and index BAM files
rule sort_and_index:
    input:
        join(config["aligned_outdir"], "{sample}.bam")
    output:
        bam = join(config["aligned_outdir"], "{sample}_sorted.bam"),
        bai = join(config["aligned_outdir"], "{sample}_sorted.bam.bai")
    threads: config["threads"]
    shell:
        """
        # Sort BAM file
        samtools sort -@ {threads} {input} -o {output.bam}
        # Index sorted BAM file
        samtools index {output.bam}
        """

# Rule to mark duplicates in BAM files
rule mark_duplicates:
    input:
        join(config["aligned_outdir"], "{sample}_sorted.bam")
    output:
        bam = join(config["dedup_outdir"], "{sample}_markdup.bam"),
        metrics = join(config["dedup_outdir"], "{sample}_markdup_metrics.txt")
    log:
        "logs/mark_duplicates/{sample}.log"
    shell:
        """
        # Mark duplicates using Picard tools
        picard MarkDuplicates I={input} O={output.bam} M={output.metrics} 2> {log}
        """

# Rule to remove duplicates from BAM files
rule remove_duplicates:
    input:
        join(config["aligned_outdir"], "{sample}_sorted.bam")
    output:
        bam = join(config["dedup_outdir"], "{sample}_dedup.bam"),
        metrics = join(config["dedup_outdir"], "{sample}_metrics.txt")
    shell:
        """
        # Remove duplicates using Picard tools
        picard MarkDuplicates I={input} O={output.bam} M={output.metrics} REMOVE_DUPLICATES=true
        """

# Rule to check if all required input files exist before peak calling
rule check_input_files:
    input:
        ip = join(config["dedup_outdir"], "{condition}_output_{replicate}_dedup.bam"),
        control = expand(join(config["dedup_outdir"], "{{condition}}_input_r{input_rep}_dedup.bam"), input_rep=[1,2,3])
    output:
        touch(join(config["peaks_outdir"], "{condition}_{replicate}.input_checked"))
    run:
        for file in input:
            if not os.path.exists(file):
                raise ValueError(f"Input file not found: {file}")

# Rule to call peaks using MACS2
rule call_peaks:
    input:
        ip = join(config["dedup_outdir"], "Medip_{condition}_output_{replicate}_markdup.bam"),
        control = join(config["dedup_outdir"], "Medip_{condition}_input_{replicate}_markdup.bam")
    output:
        narrowPeak = join(config["peaks_outdir"], "{condition}_{replicate}_peaks.narrowPeak"),
        xls = join(config["peaks_outdir"], "{condition}_{replicate}_peaks.xls")
    params:
        genome_size = config["genome_size"],
        q_value = config["macs2_qvalue"],
        outdir = config["peaks_outdir"],
        nomodel = "--nomodel",
        extsize = "--extsize 300"
    log:
        "logs/call_peaks/{condition}_{replicate}.log"
    shell:
        """
        macs2 callpeak -t {input.ip} -c {input.control} -f BAM -g {params.genome_size} \
            -n {wildcards.condition}_{wildcards.replicate} -q {params.q_value} \
            {params.nomodel} {params.extsize} \
            --outdir {params.outdir} 2> {log}
        """

# Rule to perform differential methylation analysis
rule differential_methylation:
    input:
        peaks = expand(join(config["peaks_outdir"], "{condition}_{replicate}_peaks.narrowPeak"), 
               condition=CONDITIONS, replicate=["r1", "r2", "r3"]),
        bams = expand(join(config["dedup_outdir"], "{sample}_markdup.bam"), sample=SAMPLES)
    output:
        join(config["diff_meth_outdir"], "differential_methylation_results.txt")
    log:
        "logs/differential_methylation.log"
    script:
        "scripts/differential_methylation.R"
        
# Rule to run MultiQC for aggregating QC reports
rule multiqc:
    input:
        expand(join(config["fastqc_outdir"], "{sample}_fastqc.html"), sample=SAMPLES),
        expand(join(config["fastqc_outdir"], "{sample}_trimmed_fastqc.html"), sample=SAMPLES),
        expand(join(config["dedup_outdir"], "{sample}_markdup_metrics.txt"), sample=SAMPLES)
    output:
        join(config["qc_outdir"], "multiqc_report.html")
    log:
        "logs/multiqc.log"
    shell:
        """
        multiqc {config[fastqc_outdir]} {config[dedup_outdir]} -o {config[qc_outdir]} 2> {log}
        """

# Rule to perform functional annotation of differentially methylated regions
rule functional_annotation:
    input:
        join(config["diff_meth_outdir"], "differential_methylation_results.txt")
    output:
        go_csv = join(config["func_annot_outdir"], "go_enrichment_results.csv"),
        kegg_csv = join(config["func_annot_outdir"], "kegg_enrichment_results.csv"),
        go_plot = join(config["func_annot_outdir"], "go_dotplot.pdf"),
        kegg_plot = join(config["func_annot_outdir"], "kegg_dotplot.pdf")
    script:
        "scripts/functional_annotation.R"

# Rule to create BigWig files for visualization
rule create_bigwig:
    input:
        bam = join(config["dedup_outdir"], "{sample}_markdup.bam")
    output:
        bw = join(config["bigwig_outdir"], "{sample}.bw")
    log:
        "logs/create_bigwig/{sample}.log"
    shell:
        """
        # Create BigWig file using bamCoverage
        bamCoverage -b {input.bam} -o {output.bw} --binSize 10 --normalizeUsing RPKM 2> {log}
        """

# Rule to generate fragment size distribution plot
rule fragment_size_distribution:
    input:
        expand(join(config["dedup_outdir"], "{sample}_markdup.bam"), sample=SAMPLES)
    output:
        join(config["qc_outdir"], "fragment_size_distribution.pdf")
    log:
        "logs/fragment_size_distribution.log"
    script:
        "scripts/fragment_size_distribution.R"

# Rule to calculate CpG enrichment
rule cpg_enrichment:
    input:
        expand(join(config["dedup_outdir"], "{sample}_markdup.bam"), sample=SAMPLES)
    output:
        join(config["qc_outdir"], "cpg_enrichment.txt")
    log:
        "logs/cpg_enrichment.log"
    script:
        "scripts/cpg_enrichment.R"

# Rule to assess replicate correlation
rule replicate_correlation:
    input:
        expand(join(config["dedup_outdir"], "{sample}_markdup.bam"), sample=SAMPLES)
    output:
        join(config["qc_outdir"], "replicate_correlation.pdf")
    log:
        "logs/replicate_correlation.log"
    script:
        "scripts/replicate_correlation.R"

# Rule to calculate methylation levels
rule methylation_levels:
    input:
        bams = expand(join(config["dedup_outdir"], "{sample}_markdup.bam"), sample=SAMPLES),
        peaks = expand(join(config["peaks_outdir"], "{condition}_{replicate}_peaks.narrowPeak"), 
               condition=CONDITIONS, replicate=["r1", "r2", "r3"])
    output:
        join(config["meth_level_outdir"], "methylation_levels.txt")
    log:
        "logs/methylation_levels.log"
    script:
        "scripts/methylation_levels.R"

# Rule to calculate CpG coverage and enrichment metrics
# rule medip_qc:
#     input:
#         bam = join(config["dedup_outdir"], "{sample}_markdup.bam"),
#         genome = config["genome_file"]
#     output:
#         join(config["qc_outdir"], "{sample}_medip_qc.txt")
#     shell:
#         """
#         # Calculate CpG coverage and enrichment metrics
#         MEDIPS.qc(file = {input.bam}, BSgenome = {input.genome}, extend = 300)
#         """